{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "53ec440d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a192f5",
   "metadata": {},
   "source": [
    "# Variáveis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9363542d",
   "metadata": {},
   "outputs": [],
   "source": [
    "length=100\n",
    "batch_size=32\n",
    "learning_rate=0.000001\n",
    "epocas=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b91d5130",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000,) (8937,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([9., 7., 5., 2., 9., 3., 7., 7., 4., 8., 2., 9., 5., 3., 3., 2., 6.,\n",
       "       6., 1., 4., 9., 7., 5., 2., 9., 4., 7., 8., 4., 7., 2., 9., 5., 3.,\n",
       "       3., 3., 7.])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dados_teste=np.load('dadosTeste.npy')\n",
    "dadosTreinoValidacao=np.load('dadosTreinoValidacao.npy')\n",
    "\n",
    "print(np.shape(dadosTreinoValidacao),\n",
    "np.shape(dados_teste))\n",
    "\n",
    "dadosTreinoValidacao[3:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6ea1abdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80000,) (20000,)\n"
     ]
    }
   ],
   "source": [
    "percentagem_dados=80\n",
    "\n",
    "x_train = dadosTreinoValidacao[:80000]\n",
    "\n",
    "x_validation = dadosTreinoValidacao[80000:]\n",
    "\n",
    "print(np.shape(x_train), np.shape(x_validation))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ccd44d",
   "metadata": {},
   "source": [
    "### Dados treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e5ddb614",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 100, 1)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import TimeseriesGenerator\n",
    "\n",
    "def preparar_targets(dados, length,batch_size):\n",
    "    d=5\n",
    "    salto=3\n",
    "    n=d+salto #8\n",
    "    targets=[]\n",
    "    for i in range(len(dados)):\n",
    "        soma = np.sum(dados[d:n])\n",
    "        d= d+1\n",
    "        n= n+1\n",
    "        targets.append(soma)\n",
    "    del targets[-5:]\n",
    "    \n",
    "    targets = np.expand_dims(targets, axis=1)\n",
    "    \n",
    "    new = dados[5:]\n",
    "    inputs = np.expand_dims(new, axis=1)\n",
    "\n",
    "    time_series_data = tf.keras.preprocessing.sequence.TimeseriesGenerator(inputs, targets, \n",
    "                                                                           length= length, batch_size=batch_size)\n",
    "    \n",
    "    return time_series_data\n",
    "\n",
    "time_series_data=preparar_targets(x_train,length,batch_size)\n",
    "time_series_data[0][0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b057a6f",
   "metadata": {},
   "source": [
    "### Dados Validação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "31165ec2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 100, 1)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_data = preparar_targets(x_validation,length,batch_size)\n",
    "validation_data[0][0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f667cf",
   "metadata": {},
   "source": [
    "## Rede feedfoward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4885ea07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "length = len(validation_data[0][0][0])\n",
    "print(length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9153aa4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.iter\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.decay\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.learning_rate\n",
      "Epoch 1/5\n",
      "2497/2497 - 6s - loss: 48.4789 - mae: 4.8425 - val_loss: 8.3451 - val_mae: 2.2553 - 6s/epoch - 2ms/step\n",
      "Epoch 2/5\n",
      "2497/2497 - 6s - loss: 3.9804 - mae: 1.5422 - val_loss: 1.8233 - val_mae: 1.0448 - 6s/epoch - 2ms/step\n",
      "Epoch 3/5\n",
      "2497/2497 - 6s - loss: 1.5714 - mae: 0.9726 - val_loss: 1.4498 - val_mae: 0.9308 - 6s/epoch - 2ms/step\n",
      "Epoch 4/5\n",
      "2497/2497 - 6s - loss: 1.3764 - mae: 0.9069 - val_loss: 1.2998 - val_mae: 0.8758 - 6s/epoch - 2ms/step\n",
      "Epoch 5/5\n",
      "2497/2497 - 6s - loss: 1.2543 - mae: 0.8625 - val_loss: 1.2139 - val_mae: 0.8425 - 6s/epoch - 2ms/step\n",
      "276/276 [==============================] - 1s 2ms/step - loss: 1.2453 - mae: 0.8586\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.2452565431594849, 0.8586004376411438]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Flatten(input_shape = (length,1)), tf.keras.layers.Dense(128,activation='relu')])\n",
    "\n",
    "model.add(tf.keras.layers.Dense(128,activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(1)) \n",
    "    \n",
    "optimizer=tf.keras.optimizers.Adam(0.00001)\n",
    "loss=tf.keras.losses.MeanSquaredError()\n",
    "model.compile(loss=loss, optimizer=optimizer, metrics='mae')\n",
    "\n",
    "#model.fit(time_series_data, epochs = epocas,validation_data =validation_data, shuffle= True, verbose=2)\n",
    "\n",
    "test_targets=preparar_targets(dados_teste,length,batch_size)\n",
    "model.evaluate(test_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "82d2a4b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_2 (Flatten)         (None, 100)               0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 128)               12928     \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 29,569\n",
      "Trainable params: 29,569\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "022de2ff",
   "metadata": {},
   "source": [
    "# Tunning Trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ee328727",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_tuner as kt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cd9caba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Flatten(input_shape = (length,1)), tf.keras.layers.Dense(128,activation='relu')])\n",
    "    \n",
    "    for i in range(hp.Int('layers',2,6)):\n",
    "        model.add(tf.keras.layers.Dense(\n",
    "            units=hp.Int('units_'+str(i), 50,268,step=10),\n",
    "            activation=hp.Choice('activationf_'+str(i),['relu','sigmoid'])))\n",
    "    \n",
    "    model.add(tf.keras.layers.Dense(1)) \n",
    "    \n",
    "    optimizer=tf.keras.optimizers.Adam(hp.Choice('act_',[0.00001,0.000001]))\n",
    "    loss=tf.keras.losses.MeanSquaredError()\n",
    "    model.compile(loss=loss, optimizer=optimizer, metrics='mae')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "86b1148d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Oracle from existing project .\\untitled_project\\oracle.json\n",
      "INFO:tensorflow:Reloading Tuner from .\\untitled_project\\tuner0.json\n"
     ]
    }
   ],
   "source": [
    "tuner = kt.RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_loss',\n",
    "    max_trials=5,executions_per_trial=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2d27f4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1ca275b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 Complete [00h 01m 39s]\n",
      "val_loss: 82.34087371826172\n",
      "\n",
      "Best val_loss So Far: 0.8847815990447998\n",
      "Total elapsed time: 00h 05m 04s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner.search(time_series_data,epochs=15,validation_data=validation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a76e2eb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in .\\untitled_project\n",
      "Showing 10 best trials\n",
      "<keras_tuner.engine.objective.Objective object at 0x00000206A88CDEB0>\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "conv_1_filter: 32\n",
      "layers_: 4\n",
      "conv_1_filter0: 96\n",
      "conv_2_kernel: 5\n",
      "last_dense: 80\n",
      "conv_1_filter1: 64\n",
      "conv_1_filter2: 128\n",
      "conv_1_filter3: 32\n",
      "conv_1_filter4: 64\n",
      "tuner/epochs: 5\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 0\n",
      "tuner/round: 0\n",
      "layers: 2\n",
      "units_0: 50\n",
      "activationf_0: relu\n",
      "units_1: 50\n",
      "activationf_1: relu\n",
      "act_: 1e-05\n",
      "Score: 0.881321519613266\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "conv_1_filter: 96\n",
      "layers_: 3\n",
      "conv_1_filter0: 48\n",
      "conv_2_kernel: 5\n",
      "last_dense: 112\n",
      "conv_1_filter1: 128\n",
      "conv_1_filter2: 96\n",
      "conv_1_filter3: 48\n",
      "conv_1_filter4: 64\n",
      "tuner/epochs: 5\n",
      "tuner/initial_epoch: 2\n",
      "tuner/bracket: 1\n",
      "tuner/round: 1\n",
      "tuner/trial_id: 0002\n",
      "Score: 20.007884979248047\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "conv_1_filter: 112\n",
      "layers_: 4\n",
      "conv_1_filter0: 80\n",
      "conv_2_kernel: 2\n",
      "last_dense: 128\n",
      "conv_1_filter1: 96\n",
      "conv_1_filter2: 32\n",
      "conv_1_filter3: 64\n",
      "conv_1_filter4: 48\n",
      "tuner/epochs: 5\n",
      "tuner/initial_epoch: 2\n",
      "tuner/bracket: 1\n",
      "tuner/round: 1\n",
      "tuner/trial_id: 0003\n",
      "Score: 24.55327033996582\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "conv_1_filter: 96\n",
      "layers_: 5\n",
      "conv_1_filter0: 64\n",
      "conv_2_kernel: 2\n",
      "last_dense: 128\n",
      "conv_1_filter1: 48\n",
      "conv_1_filter2: 32\n",
      "conv_1_filter3: 96\n",
      "conv_1_filter4: 112\n",
      "tuner/epochs: 5\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 0\n",
      "tuner/round: 0\n",
      "Score: 24.73929214477539\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "conv_1_filter: 112\n",
      "layers_: 5\n",
      "conv_1_filter0: 32\n",
      "conv_2_kernel: 5\n",
      "last_dense: 64\n",
      "conv_1_filter1: 80\n",
      "conv_1_filter2: 80\n",
      "conv_1_filter3: 48\n",
      "conv_1_filter4: 80\n",
      "tuner/epochs: 5\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 0\n",
      "tuner/round: 0\n",
      "Score: 25.17340850830078\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "conv_1_filter: 96\n",
      "layers_: 4\n",
      "conv_1_filter0: 48\n",
      "conv_2_kernel: 5\n",
      "last_dense: 112\n",
      "conv_1_filter1: 32\n",
      "conv_1_filter2: 128\n",
      "conv_1_filter3: 112\n",
      "conv_1_filter4: 96\n",
      "tuner/epochs: 2\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 1\n",
      "tuner/round: 0\n",
      "Score: 25.33062744140625\n"
     ]
    }
   ],
   "source": [
    "tuner.results_summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
